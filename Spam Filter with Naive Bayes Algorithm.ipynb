{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam filter using Naive Bayes Algorithm\n",
    "\n",
    "<p style=\"font-size:17px;text-align:justify\">In this work I will build a multinominal Naive Bayes algorithm in order to sort the messages from <a href=\"https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\">SMSSpamCollection</a> dataset based on wether the message is a SPAM or not.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_colwidth', 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                          SMS  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la...  \n",
       "1                                               Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Tex...  \n",
       "3                           U dun say so early hor... U c already then say...  \n",
       "4               Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the dataset, naming the columns 'label' and 'SMS'.\n",
    "sms = pd.read_csv(\"SMSSpamCollection\", sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;font-size:15px\">There are 5572 messages in the dataset, out of which 13.4% are SPAM</p>\n",
    "<hr style=\"border-width:1px;border-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;font-size:15px\">Software like this needs evaluation, to see how accurate it is. To escape from any form of biased testing, I'm going to define the test before creating the algorithm.\n",
    "<br>\n",
    "The dataset will be divided into two parts in ratio of 80:20. The bigger chunk will be used to \"teach\" the algorithm, the smaller one will be the test. The final algorithm should have the accuracy of 80%.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a randomized dataset to ensure the two chunks for feeding and testing are representative.\n",
    "sms_randomized = sms.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_80 = round(len(sms_randomized) * 0.8)\n",
    "sms_feed = sms_randomized.iloc[0:per_80,:].reset_index(drop=True)\n",
    "sms_test = sms_randomized.iloc[per_80:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_feed['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.868043\n",
       "spam    0.131957\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_test['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;font-size:15px\">Now there are two datasets, both with roughly the same ham/spam ratio as the original.<p>\n",
    "<hr style=\"border-width:1.5px;border-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;font-size:15px\">To make the calculations easier, the dataset needs to be cleaned in a proper way. The approach that is taken here consists of creating a separate column for each word in a list of all the unique words, and each row will have the count of this word in the given message.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting all punctuation and converting the strings to lowercase.\n",
    "sms_feed['SMS'] = sms_feed['SMS'].str.replace(pat='\\W', repl=\" \").str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting each message to a list of words.\n",
    "sms_feed['SMS'] = sms_feed['SMS'].str.split()\n",
    "#creating a vocabulary with each unique word.\n",
    "vocabulary = []\n",
    "for i in sms_feed['SMS']:\n",
    "    for j in i:\n",
    "        vocabulary.append(j)\n",
    "vocabulary = list(set(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 7783)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dictionary with a word count per sms\n",
    "word_counts_per_sms = {unique_word: [0] * len(sms_feed['SMS']) for unique_word in vocabulary}\n",
    "for index, sms in enumerate(sms_feed['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "#converting the dictionary to a pandas DataFrame.\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>sinco</th>\n",
       "      <th>foundurself</th>\n",
       "      <th>useless</th>\n",
       "      <th>enemy</th>\n",
       "      <th>lock</th>\n",
       "      <th>7ish</th>\n",
       "      <th>car</th>\n",
       "      <th>tv</th>\n",
       "      <th>...</th>\n",
       "      <th>table</th>\n",
       "      <th>worry</th>\n",
       "      <th>89123</th>\n",
       "      <th>freek</th>\n",
       "      <th>toll</th>\n",
       "      <th>pictures</th>\n",
       "      <th>yup</th>\n",
       "      <th>oil</th>\n",
       "      <th>package</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me, moan]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a, card, on, da, present, l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ham</td>\n",
       "      <td>[sorry, i, ll, call, later, in, meeting, any, thing, related, to, trade...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>ham</td>\n",
       "      <td>[babe, i, fucking, love, you, too, you, know, fuck, it, was, so, good, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>spam</td>\n",
       "      <td>[u, ve, been, selected, to, stay, in, 1, of, 250, top, british, hotels,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ham</td>\n",
       "      <td>[hello, my, boytoy, geeee, i, miss, you, already, and, i, just, woke, u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>ham</td>\n",
       "      <td>[wherre, s, my, boytoy]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4458 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  \\\n",
       "0      ham   \n",
       "1      ham   \n",
       "2      ham   \n",
       "3      ham   \n",
       "4      ham   \n",
       "...    ...   \n",
       "4453   ham   \n",
       "4454   ham   \n",
       "4455  spam   \n",
       "4456   ham   \n",
       "4457   ham   \n",
       "\n",
       "                                                                             SMS  \\\n",
       "0                                              [yep, by, the, pretty, sculpture]   \n",
       "1                           [yes, princess, are, you, going, to, make, me, moan]   \n",
       "2                                                [welp, apparently, he, retired]   \n",
       "3                                                                       [havent]   \n",
       "4     [i, forgot, 2, ask, ü, all, smth, there, s, a, card, on, da, present, l...   \n",
       "...                                                                          ...   \n",
       "4453  [sorry, i, ll, call, later, in, meeting, any, thing, related, to, trade...   \n",
       "4454  [babe, i, fucking, love, you, too, you, know, fuck, it, was, so, good, ...   \n",
       "4455  [u, ve, been, selected, to, stay, in, 1, of, 250, top, british, hotels,...   \n",
       "4456  [hello, my, boytoy, geeee, i, miss, you, already, and, i, just, woke, u...   \n",
       "4457                                                     [wherre, s, my, boytoy]   \n",
       "\n",
       "      sinco  foundurself  useless  enemy  lock  7ish  car  tv  ...  table  \\\n",
       "0         0            0        0      0     0     0    0   0  ...      0   \n",
       "1         0            0        0      0     0     0    0   0  ...      0   \n",
       "2         0            0        0      0     0     0    0   0  ...      0   \n",
       "3         0            0        0      0     0     0    0   0  ...      0   \n",
       "4         0            0        0      0     0     0    0   0  ...      0   \n",
       "...     ...          ...      ...    ...   ...   ...  ...  ..  ...    ...   \n",
       "4453      0            0        0      0     0     0    0   0  ...      0   \n",
       "4454      0            0        0      0     0     0    0   0  ...      0   \n",
       "4455      0            0        0      0     0     0    0   0  ...      0   \n",
       "4456      0            0        0      0     0     0    0   0  ...      0   \n",
       "4457      0            0        0      0     0     0    0   0  ...      0   \n",
       "\n",
       "      worry  89123  freek  toll  pictures  yup  oil  package  original  \n",
       "0         0      0      0     0         0    0    0        0         0  \n",
       "1         0      0      0     0         0    0    0        0         0  \n",
       "2         0      0      0     0         0    0    0        0         0  \n",
       "3         0      0      0     0         0    0    0        0         0  \n",
       "4         0      0      0     0         0    0    0        0         0  \n",
       "...     ...    ...    ...   ...       ...  ...  ...      ...       ...  \n",
       "4453      0      0      0     0         0    0    0        0         0  \n",
       "4454      0      0      0     0         0    0    0        0         0  \n",
       "4455      0      0      0     0         0    0    0        0         0  \n",
       "4456      0      0      0     0         0    0    0        0         0  \n",
       "4457      0      0      0     0         0    0    0        0         0  \n",
       "\n",
       "[4458 rows x 7785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenating the new dataframe with the training one, so the labels and messages are present.\n",
    "sms_feed_clean = pd.concat([sms_feed, word_counts], axis=1)\n",
    "sms_feed_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:1.5px;border-color:black\">\n",
    "<p style=\"text-align:justify;font-size:15px\">Now that the dataset is clean, it is time to start creating the spam filter.\n",
    "<br>\n",
    "First of all, the probabilities of receiving a spam and non-spam messages need to be calculated. Also the counts of words in all of the spam and non-spam messages, along with vocabulary count.\n",
    "<br>\n",
    "In this method, when calculating P(Wi|Spam) and P(Wi|Ham), the equations need an additional, smoothing parameter - alpha. In this case it will equal to 1.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating constants that will be used in calculating final probabilities\n",
    "p_spam = len(sms_feed_clean[sms_feed_clean['Label']=='spam']) / sms_feed_clean.shape[0]\n",
    "p_ham = 1 - p_spam\n",
    "n_spam = 0\n",
    "for i in sms_feed_clean.loc[sms_feed_clean['Label']=='spam', 'SMS']:\n",
    "    n_spam += len(i)\n",
    "\n",
    "n_ham = 0\n",
    "for i in sms_feed_clean.loc[sms_feed_clean['Label']=='ham', 'SMS']:\n",
    "    n_ham += len(i)\n",
    "\n",
    "n_vocabulary = len(vocabulary)\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionaries with probabilities for each word in both spam and ham messages.\n",
    "p_wi_given_spam = {}\n",
    "p_wi_given_non_spam = {}\n",
    "for i in vocabulary:\n",
    "    p_wi_given_spam[i] = 0\n",
    "    p_wi_given_non_spam[i] = 0\n",
    "\n",
    "spam_training = sms_feed_clean[sms_feed_clean['Label']=='spam']\n",
    "ham_training = sms_feed_clean[sms_feed_clean['Label']=='ham']\n",
    "\n",
    "for word in vocabulary:\n",
    "    p_wi_given_spam[word] = (spam_training[word].sum() + alpha)/(n_spam + alpha * n_vocabulary)\n",
    "    p_wi_given_non_spam[word] = (ham_training[word].sum() + alpha)/(n_ham + alpha * n_vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function that calculates probabilities for given message in spam and ham messages and assigns the message to either one of the labels.\n",
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    #cleaning the message, so it is ready for use\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    #calculating probabilities for message being a spam or non-spam.\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for i in message:\n",
    "        if i in p_wi_given_spam:\n",
    "            p_spam_given_message *= p_wi_given_spam[i]\n",
    "        if i in p_wi_given_non_spam:\n",
    "            p_ham_given_message *= p_wi_given_non_spam[i]\n",
    "            \n",
    "    #comparing the probabilities and returning proper labels.\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing with message that is obviously a spam.\n",
    "classify('WINNER!! This is the secret code to unlock the money: C3421')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing with message that is obviously not a spam.\n",
    "classify('Sounds good, Tom, then see u there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Orange camera/video phones fo...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult to type</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega shop in asda counts as cele...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                          SMS  \\\n",
       "0                                   Later i guess. I needa do mcat study too.   \n",
       "1                                      But i haf enuff space got like 4 mb...   \n",
       "2  Had your mobile 10 mths? Update to latest Orange camera/video phones fo...   \n",
       "3                       All sounds good. Fingers . Makes it difficult to type   \n",
       "4  All done, all handed in. Don't know if mega shop in asda counts as cele...   \n",
       "\n",
       "  predicted  \n",
       "0       ham  \n",
       "1       ham  \n",
       "2      spam  \n",
       "3       ham  \n",
       "4       ham  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_test['predicted'] = sms_test['SMS'].apply(classify)\n",
    "sms_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874326750448833"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = sms_test.shape[0]\n",
    "for i in sms_test.iterrows():\n",
    "    if i[1]['Label'] == i[1]['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As can be seen above, accuracy of the model is almost 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
